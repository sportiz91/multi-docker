upstream client {
    server client:3000;
}

upstream api {
    server api:5000; 
}

server {
    listen 80;

    location / {
        proxy_pass http://client;
    }

    location /ws {
        proxy_pass http://client;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "Upgrade";
    }

    location /api {
        rewrite /api/(.*) /$1 break;
        proxy_pass http://api;
    }
}

#126. Routing with Nginx
#Para setupear nginx y darle estas reglas, vamos a poner algo que se llama default.conf. Es un file especial que se agrega a una nginx
#Image. Este file agrega un poco de configuración que implementan las routing rules. 
#Primero, le vamos a decir a nginx que hay un "upstream server" en el client:3000 y otro "upstream server" en el client:5000.
#Nginx mira por requests provenientes del outside world. Luego, las routea al server apropiado. Estos servidores (React Server + 
#Express Server), se encuentran detrás de nginx. Es decir, no podremos acceder a dichos servidores a menos que pasemos por nginx.
#Entonces, estos se llaman los "Upstream Servers". Es decir, son servidores a los que nginx puede opcionalmente redirigir tráfico.
#Recordemos que cuando hicimos la implementación del servidor, dentro de la carpeta de servidor e index.js, veremos que estaba
#Escuchando en el puerto 5000. Es decir, el servidor estaba escuchando tráfico en el puerto 5000.
#Pero, client:3000 y server:5000 son addresses. Entonces, Client y Server son actually hostnames, o URLs, que nginx redirigirá tráfico
#Luego, vamos a escuchar en el puerto 80 adentro del container. 
#Luego de escuchar en el port 80 adentro del contaidner, vamos a poner los dos roles:
#Si alguien llega al "/" o a la root route, los vamos a mandar al Client upstream. Y si alguien llega al /api, lo vamos a mandar al
#Server upstream.
#Al default.conf luego lo vamos a transformar en una Docker Image. 
#Dentro de nginx, server es una protected keyword.
#Es por eso que renameamos tanto en este file, como en docker compose, el server service por "api" service.
#Dentro de server line, estamos diciendo que escuche en el puerto 80. Si la request viene a la route forward slash, entonces tendremos
#Que redirigir la request al http://client. 
#Dentro del rewrite, tenemos en una regex, que básicamente me dice si la route matchea con /api/(.*) -> cualquier otra cosa,
#Entonces tendremos que cambiar por /$1 break. /$1 es una reference. Básicamente toma la regex que matcheó anteriormente y devuelve
#Justamente eso. 
#El break keyword al final es una directiva. Básicamente quiere decir que no apliquemos ninguna otra rewrite rule. 

#Q: What is nginx, can you explain me in detail?
#A: 
#NGINX (pronounced "engine-x") is a free and open-source, high-performance web server and reverse proxy server.
#It is widely used for serving web applications, reverse proxying, caching, load balancing, media streaming, and more.
#NGINX was created to address the scalability and performance limitations of traditional Apache web servers.
#It is known for its high performance, stability, and low resource consumption, making it a popular choice 
#for high-traffic websites and applications.
#In addition to being a web server, NGINX can also act as a reverse proxy, which means it can 
#distribute incoming traffic across multiple servers
#providing a high level of fault tolerance and scalability. NGINX can also 
#be used as a load balancer, SSL termination proxy, and a caching server.
#NGINX is highly configurable and supports a variety of modules and extensions.
#It can be configured using a simple text-based configuration file, which allows for easy customization and flexibility.
#Overall, NGINX is a powerful and flexible web server and reverse proxy server that offers high performance, stability, and scalability
#It is widely used by large enterprises, web applications, and websites to handle high volumes of 
#traffic and deliver content quickly and reliably.

#Q: Can you explain me what reverse proxy means in nginx server? Can you provide some examples to better ilustrate?
#A:
#In the context of an Nginx server, a reverse proxy is a server that sits between the client and the backend server(s).
#It accepts incoming requests from clients and forwards 
#them to the appropriate backend server based on the request's URL or other rules.
#Reverse proxying is a common use case for Nginx.
#For example, if you have multiple web servers serving different applications, 
#you can set up an Nginx server to act as a reverse proxy that routes requests to the correct server based on the URL.
#Here's an example configuration that uses Nginx as a reverse proxy for two different Node.js applications:
#http {
#  upstream node_app1 {
#    server 127.0.0.1:3000;
#  }
  
#  upstream node_app2 {
#    server 127.0.0.1:4000;
#  }

#  server {
#    listen 80;
    
#    location /app1 {
#      proxy_pass http://node_app1/;
#    }
    
#    location /app2 {
#      proxy_pass http://node_app2/;
#    }
#  }
#}
#In this example, Nginx is set up to listen on port 80 for incoming requests. 
#If a request comes in for the /app1 URL, Nginx will forward the request to the Node.js application running on port 3000.
#If a request comes in for the /app2 URL, Nginx will forward the request to the Node.js application running on port 4000.
#Using a reverse proxy can provide several benefits, including improved security, better scalability, 
#and easier management of multiple backend servers.

#Q: I have the following scenario: I have a React App and an Express API Server. I'm using Nginx to route 
#certain requests to the React App Server, and other routes to the Express API Server. 
#Is that a common scenario in development environment with docker-compose?
#A:
#Yes, it's a common scenario to have a React App and an Express API Server 
#running on different ports and using Nginx as a reverse proxy to route requests to the appropriate server.
#This setup is often used in development environments, as well as in production environments, 
#to provide a unified interface for clients to interact with the application.
#By using Docker Compose, it becomes easier to manage the containers running the different components of the application,
#and to ensure that they are running in the same network and can communicate with each other.

#Q: Can you explain me in detail what default.conf is on nginx? Can you explain me the syntax of the file? Can you provide examples?
#A:
#default.conf is a configuration file in Nginx that is used to define the default settings for a server block.
#It specifies how incoming HTTP requests should be handled by the server.
#The syntax of default.conf typically follows this structure:
#server {
#    listen [port number];
#    server_name [domain name];

#    location [URI] {
#        [directive] [parameter];
#        ...
#    }

#    ...
#}
#listen specifies the port on which the server listens for incoming requests.
#server_name specifies the domain name that the server should respond to.
#location specifies the URI that the server block should handle.
#directive specifies an instruction to Nginx to handle the request in a certain way.
#parameter specifies the value of the directive.
#Here is an example of a default.conf file:
#server {
#    listen 80;
#    server_name example.com;

#    location /api {
#        proxy_pass http://api-server:3000;
#    }

#    location / {
#        root /var/www/html;
#        index index.html;
#    }
#}
#In this example, the server block listens on port 80 for incoming requests to the example.com domain
#Requests to the /api URI are forwarded to the http://api-server:3000 server.
#Requests to any other URI are served by files in the /var/www/html directory.

#Q: Can you explain me in detail what an "upstream server" is in nginx?
#A: 
#In Nginx, an "upstream server" refers to a group of backend servers that can handle requests passed on by Nginx.
#When Nginx receives a request from a client, it forwards the request to the upstream servers for processing.
#This enables load balancing and high availability for the backend servers.
#An upstream server can be defined in the Nginx configuration using the upstream directive. 
#The upstream directive defines a group of backend servers 
#and their respective IP addresses or hostnames, as well as any parameters that Nginx should use to balance requests among the servers.
#Here's an example of an upstream server definition in the Nginx configuration:
#http {
#  upstream backend {
#    server backend1.example.com;
#    server backend2.example.com;
#    server backend3.example.com;
#  }
#  ...
#}
#In this example, the upstream directive defines a group of backend servers named "backend", 
#which includes three servers with hostnames "backend1.example.com", 
#"backend2.example.com", and "backend3.example.com"
#Nginx will automatically balance requests among these servers using a default round-robin algorithm.
#Other load balancing algorithms can also be specified, 
#such as IP hash or least connections, by adding additional parameters to the upstream directive.
#Once an upstream server is defined, it can be referenced in a server block to handle requests for a particular location. For example:
#http {
#  upstream backend {
#    server backend1.example.com;
#    server backend2.example.com;
#    server backend3.example.com;
#  }

#  server {
#    listen 80;
#    server_name example.com;

#    location / {
#      proxy_pass http://backend;
#    }
#  }
#}
#In this example, the location block routes requests to the "backend" upstream server defined earlier.
#The proxy_pass directive forwards requests to the backend servers in a round-robin fashion by default.

#Q: Can you explain me in detail the following default.conf file? 
#upstream client {
#    server client:3000;
#}

#upstream api {
#    server api:5000; 
#}

#server {
#    listen 80;

#    location / {
#        proxy_pass http://client;
#    }

#    location /api {
#        rewrite /api/(.*) /$1 break;
#        proxy_pass http://api;
#    }
#}
#A:
#upstream client { server client:3000; }:
#This defines an upstream server called client, and specifies that it can be reached at the hostname client and the port 3000.
#upstream api { server api:5000; }:
#This defines another upstream server called api, and specifies that it can be reached at the hostname api and the port 5000.
#server { listen 80;:
#This defines a server block that listens on port 80, which is the default HTTP port.
#location / { proxy_pass http://client; }:
#This is a location block that handles requests to the root URL /
#It uses the proxy_pass directive to pass all requests to the client upstream server that we defined earlier.
#location /api { rewrite /api/(.*) /$1 break; proxy_pass http://api; }:
#This is another location block that handles requests to the /api path. It uses the rewrite directive to remove 
#the /api prefix from the request URI, and then passes the request to the api upstream server that we defined earlier.
#Overall, this configuration file is acting as a reverse proxy, directing requests to the appropriate backend server 
#based on the URL path.
#Requests to the root URL (/) are directed to the client server, which is presumably serving up the React app
#while requests to the /api path are directed to the api server, which is serving up the Express API.

#Q: Can you explain me the proxy_pass directive in detail?
#A: The proxy_pass directive is a core directive in Nginx that is used to pass requests to an upstream server.
#When Nginx receives a request from a client, it can proxy that request to an upstream server 
#that is defined in the proxy_pass directive.
#This is useful when you have multiple servers running different applications and want to route requests based on specific URLs.
#The proxy_pass directive is usually used within a location block, which defines a specific URL pattern to match.
#For example, in the following location block:
#location /api {
#    proxy_pass http://localhost:3000;
#}
#All requests to URLs starting with /api will be proxied to http://localhost:3000.
#The proxy_pass directive can also include additional parameters, such as:
#proxy_set_header: used to set additional headers in the request being sent to the upstream server.
#proxy_redirect: used to modify the Location and Refresh headers in the response from the upstream server.
#proxy_intercept_errors: used to redirect error responses from the upstream server to an error handling location.
#Overall, the proxy_pass directive is a powerful tool for routing requests in 
#Nginx and is commonly used in conjunction with upstream servers to balance load and improve performance.

#Q: Can you explain me in detail the rewrite directive?
#A: 
#The rewrite directive is used to modify parts of a URL before passing it to the proxy server.
#It can be used to remove or add parts of the URL, or to change the URL entirely. The syntax of the rewrite directive is as follows:
#rewrite regex replacement [flag];
#Here, regex is a regular expression that matches the part of the URL to be replaced, 
#and replacement is the new value to replace it with.
#The flag parameter is optional, and can be used to specify options for the rewrite operation, such as case-insensitivity.
#For example, in the following configuration:
#location /api {
#    rewrite /api/(.*) /$1 break;
#    proxy_pass http://api;
#}
#The rewrite directive is used to remove the /api prefix from the URL before passing it to the proxy server.
#The regular expression /(.*) matches any characters after the /api/ prefix, 
#and the replacement string /$1 replaces it with the captured group
#effectively removing the /api prefix. The break flag is used to prevent any further 
#processing of the rewrite rules after this rule has been applied.
#So, if a request is made to http://example.com/api/getData, the rewrite 
#directive will modify the URL to http://example.com/getData before passing it to the proxy server.

#Q: Can you explain me in detail what the $1 is in the above example?
#A: 
#In the above example, the $1 is a capture group that is used in conjunction with the rewrite directive in the location /api block.
#The rewrite directive is used to modify the URL that is sent to the upstream server.
#In this case, the rewrite directive is being used to strip the /api prefix from the URL.
#The regular expression /(.*) matches any character sequence that appears after the /api/ prefix, 
#and the $1 refers to the matched sequence in parentheses.
#For example, if the client sends a request to http://localhost/api/users, the rewrite directive 
#will modify the URL to http://localhost/users before passing it to the upstream server. 
#The $1 in the rewrite directive will capture the string users from the original URL and insert it in the modified URL.

#Q: Can you show me different regex examples in the rewrite directive?
#A: Rewrite a specific URL to a new URL:
#rewrite ^/old-url$ /new-url permanent;
#This regex matches the exact URL /old-url and redirects it to /new-url.
#Rewrite a URL with a variable path to a new URL:
#rewrite ^/products/(\d+)$ /catalog/product?id=$1 last;
#This regex matches any URL that starts with /products/ followed by 
#one or more digits and rewrites it to /catalog/product?id= followed by the captured digits.
#Remove a file extension from a URL:
#rewrite ^/(.*)\.html$ /$1 permanent;
#This regex matches any URL that ends with .html and removes the extension from the URL.
#Redirect HTTP requests to HTTPS:
#rewrite ^ https://$server_name$request_uri? permanent;
#This regex matches any HTTP request and redirects it to the same URL with https:// instead of http://.
#Rewrite a URL with a query string to a new URL:
#rewrite ^/search\?q=(.*)$ /catalog/search?q=$1 permanent;
#This regex matches any URL that starts with /search?q= followed by any characters and rewrites 
#it to /catalog/search?q= followed by the captured characters.
#Note that these are just a few examples, and there are many more ways to use regular 
#expressions in the rewrite directive of an nginx reverse proxy.

#Q: What are the permanent and last instructions on the above examples? What is the break; instruction?
#A:
#permanent and last are both flags that can be used in the rewrite directive to control how the server handles the rewritten request.
#The permanent flag indicates that the request should be redirected permanently (i.e., with an HTTP status code 
#of 301 or 308), meaning that any future requests to the original URL will be automatically redirected to the new URL.
#This is often used for situations where a resource has moved to a new location permanently.
#The last flag indicates that no further processing of the current request should be done after the rewrite has been applied.
#This can be useful in situations where multiple rewrite rules need to be applied to a request in sequence.
#When the last flag is used, Nginx will stop processing the current request and apply any subsequent rules to the newly rewritten URL.
#The break flag, on the other hand, is used to stop processing any more rewrite rules and proceed to 
#the next directive in the configuration file.
#This can be useful in cases where a specific condition is met and no further rewrite rules need to be applied.
#Note that it's important to use these flags appropriately, as improper use can result in unexpected behavior or even server errors.

#Q: So, what's the difference between last and break in the rewrite instruction of an nginx proxy server? Aren't they the same?
#A:
#In the context of the rewrite instruction in an Nginx proxy server, "last" and "break" have slightly different meanings.
#The "rewrite" instruction in Nginx is used to modify the URL of a request before it is processed by the server.
#It is often used in conjunction with proxy_pass to redirect requests to a different location.
#When "last" is used in a rewrite instruction, it indicates that the current rewrite rule should be the last one evaluated.
#This means that if the current rule matches the URL, no further rules will be evaluated and the rewritten URL will be used.
#On the other hand, "break" is used to terminate the evaluation of all rewrite rules and proceed 
#to the next Nginx configuration directive.
#This means that if "break" is used in a rewrite instruction, no further rewrite rules 
#will be evaluated and the original URL will be used.
#So, in summary, "last" and "break" have different meanings in the context of the rewrite instruction in an Nginx proxy server.
#"last" means that the current rewrite rule is the last one evaluated, while "break" terminates the evaluation of all rewrite 
#rules and proceeds to the next configuration directive.















